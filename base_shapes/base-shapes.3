# This is a base shape file encoded in yaml
# - `null` indicates a dimension is "finite", i.e. a non-"width" dimension
# - a number indicates the base dimension of an "infinite" dimension, i.e. some notion of "width"
sequential.0.word_embeddings.weight:
- null
- 552
sequential.10.attention.dense.bias:
- 552
sequential.10.attention.dense.weight:
- 552
- 552
sequential.10.attention.query_key_value.bias:
- 1656
sequential.10.attention.query_key_value.weight:
- 1656
- 552
sequential.10.input_layernorm.bias:
- 552
sequential.10.input_layernorm.weight:
- 552
sequential.10.mlp.dense_4h_to_h.bias:
- 552
sequential.10.mlp.dense_4h_to_h.weight:
- 552
- 2208
sequential.10.mlp.dense_h_to_4h.bias:
- 2208
sequential.10.mlp.dense_h_to_4h.weight:
- 2208
- 552
sequential.10.post_attention_layernorm.bias:
- 552
sequential.10.post_attention_layernorm.weight:
- 552
sequential.11.attention.dense.bias:
- 552
sequential.11.attention.dense.weight:
- 552
- 552
sequential.11.attention.query_key_value.bias:
- 1656
sequential.11.attention.query_key_value.weight:
- 1656
- 552
sequential.11.input_layernorm.bias:
- 552
sequential.11.input_layernorm.weight:
- 552
sequential.11.mlp.dense_4h_to_h.bias:
- 552
sequential.11.mlp.dense_4h_to_h.weight:
- 552
- 2208
sequential.11.mlp.dense_h_to_4h.bias:
- 2208
sequential.11.mlp.dense_h_to_4h.weight:
- 2208
- 552
sequential.11.post_attention_layernorm.bias:
- 552
sequential.11.post_attention_layernorm.weight:
- 552
sequential.12.attention.dense.bias:
- 552
sequential.12.attention.dense.weight:
- 552
- 552
sequential.12.attention.query_key_value.bias:
- 1656
sequential.12.attention.query_key_value.weight:
- 1656
- 552
sequential.12.input_layernorm.bias:
- 552
sequential.12.input_layernorm.weight:
- 552
sequential.12.mlp.dense_4h_to_h.bias:
- 552
sequential.12.mlp.dense_4h_to_h.weight:
- 552
- 2208
sequential.12.mlp.dense_h_to_4h.bias:
- 2208
sequential.12.mlp.dense_h_to_4h.weight:
- 2208
- 552
sequential.12.post_attention_layernorm.bias:
- 552
sequential.12.post_attention_layernorm.weight:
- 552
sequential.13.attention.dense.bias:
- 552
sequential.13.attention.dense.weight:
- 552
- 552
sequential.13.attention.query_key_value.bias:
- 1656
sequential.13.attention.query_key_value.weight:
- 1656
- 552
sequential.13.input_layernorm.bias:
- 552
sequential.13.input_layernorm.weight:
- 552
sequential.13.mlp.dense_4h_to_h.bias:
- 552
sequential.13.mlp.dense_4h_to_h.weight:
- 552
- 2208
sequential.13.mlp.dense_h_to_4h.bias:
- 2208
sequential.13.mlp.dense_h_to_4h.weight:
- 2208
- 552
sequential.13.post_attention_layernorm.bias:
- 552
sequential.13.post_attention_layernorm.weight:
- 552
sequential.14.attention.dense.bias:
- 552
sequential.14.attention.dense.weight:
- 552
- 552
sequential.14.attention.query_key_value.bias:
- 1656
sequential.14.attention.query_key_value.weight:
- 1656
- 552
sequential.14.input_layernorm.bias:
- 552
sequential.14.input_layernorm.weight:
- 552
sequential.14.mlp.dense_4h_to_h.bias:
- 552
sequential.14.mlp.dense_4h_to_h.weight:
- 552
- 2208
sequential.14.mlp.dense_h_to_4h.bias:
- 2208
sequential.14.mlp.dense_h_to_4h.weight:
- 2208
- 552
sequential.14.post_attention_layernorm.bias:
- 552
sequential.14.post_attention_layernorm.weight:
- 552
sequential.15.attention.dense.bias:
- 552
sequential.15.attention.dense.weight:
- 552
- 552
sequential.15.attention.query_key_value.bias:
- 1656
sequential.15.attention.query_key_value.weight:
- 1656
- 552
sequential.15.input_layernorm.bias:
- 552
sequential.15.input_layernorm.weight:
- 552
sequential.15.mlp.dense_4h_to_h.bias:
- 552
sequential.15.mlp.dense_4h_to_h.weight:
- 552
- 2208
sequential.15.mlp.dense_h_to_4h.bias:
- 2208
sequential.15.mlp.dense_h_to_4h.weight:
- 2208
- 552
sequential.15.post_attention_layernorm.bias:
- 552
sequential.15.post_attention_layernorm.weight:
- 552
sequential.16.attention.dense.bias:
- 552
sequential.16.attention.dense.weight:
- 552
- 552
sequential.16.attention.query_key_value.bias:
- 1656
sequential.16.attention.query_key_value.weight:
- 1656
- 552
sequential.16.input_layernorm.bias:
- 552
sequential.16.input_layernorm.weight:
- 552
sequential.16.mlp.dense_4h_to_h.bias:
- 552
sequential.16.mlp.dense_4h_to_h.weight:
- 552
- 2208
sequential.16.mlp.dense_h_to_4h.bias:
- 2208
sequential.16.mlp.dense_h_to_4h.weight:
- 2208
- 552
sequential.16.post_attention_layernorm.bias:
- 552
sequential.16.post_attention_layernorm.weight:
- 552
sequential.17.attention.dense.bias:
- 552
sequential.17.attention.dense.weight:
- 552
- 552
sequential.17.attention.query_key_value.bias:
- 1656
sequential.17.attention.query_key_value.weight:
- 1656
- 552
sequential.17.input_layernorm.bias:
- 552
sequential.17.input_layernorm.weight:
- 552
sequential.17.mlp.dense_4h_to_h.bias:
- 552
sequential.17.mlp.dense_4h_to_h.weight:
- 552
- 2208
sequential.17.mlp.dense_h_to_4h.bias:
- 2208
sequential.17.mlp.dense_h_to_4h.weight:
- 2208
- 552
sequential.17.post_attention_layernorm.bias:
- 552
sequential.17.post_attention_layernorm.weight:
- 552
sequential.18.attention.dense.bias:
- 552
sequential.18.attention.dense.weight:
- 552
- 552
sequential.18.attention.query_key_value.bias:
- 1656
sequential.18.attention.query_key_value.weight:
- 1656
- 552
sequential.18.input_layernorm.bias:
- 552
sequential.18.input_layernorm.weight:
- 552
sequential.18.mlp.dense_4h_to_h.bias:
- 552
sequential.18.mlp.dense_4h_to_h.weight:
- 552
- 2208
sequential.18.mlp.dense_h_to_4h.bias:
- 2208
sequential.18.mlp.dense_h_to_4h.weight:
- 2208
- 552
sequential.18.post_attention_layernorm.bias:
- 552
sequential.18.post_attention_layernorm.weight:
- 552
sequential.19.attention.dense.bias:
- 552
sequential.19.attention.dense.weight:
- 552
- 552
sequential.19.attention.query_key_value.bias:
- 1656
sequential.19.attention.query_key_value.weight:
- 1656
- 552
sequential.19.input_layernorm.bias:
- 552
sequential.19.input_layernorm.weight:
- 552
sequential.19.mlp.dense_4h_to_h.bias:
- 552
sequential.19.mlp.dense_4h_to_h.weight:
- 552
- 2208
sequential.19.mlp.dense_h_to_4h.bias:
- 2208
sequential.19.mlp.dense_h_to_4h.weight:
- 2208
- 552
sequential.19.post_attention_layernorm.bias:
- 552
sequential.19.post_attention_layernorm.weight:
- 552
sequential.2.attention.dense.bias:
- 552
sequential.2.attention.dense.weight:
- 552
- 552
sequential.2.attention.query_key_value.bias:
- 1656
sequential.2.attention.query_key_value.weight:
- 1656
- 552
sequential.2.input_layernorm.bias:
- 552
sequential.2.input_layernorm.weight:
- 552
sequential.2.mlp.dense_4h_to_h.bias:
- 552
sequential.2.mlp.dense_4h_to_h.weight:
- 552
- 2208
sequential.2.mlp.dense_h_to_4h.bias:
- 2208
sequential.2.mlp.dense_h_to_4h.weight:
- 2208
- 552
sequential.2.post_attention_layernorm.bias:
- 552
sequential.2.post_attention_layernorm.weight:
- 552
sequential.20.attention.dense.bias:
- 552
sequential.20.attention.dense.weight:
- 552
- 552
sequential.20.attention.query_key_value.bias:
- 1656
sequential.20.attention.query_key_value.weight:
- 1656
- 552
sequential.20.input_layernorm.bias:
- 552
sequential.20.input_layernorm.weight:
- 552
sequential.20.mlp.dense_4h_to_h.bias:
- 552
sequential.20.mlp.dense_4h_to_h.weight:
- 552
- 2208
sequential.20.mlp.dense_h_to_4h.bias:
- 2208
sequential.20.mlp.dense_h_to_4h.weight:
- 2208
- 552
sequential.20.post_attention_layernorm.bias:
- 552
sequential.20.post_attention_layernorm.weight:
- 552
sequential.21.attention.dense.bias:
- 552
sequential.21.attention.dense.weight:
- 552
- 552
sequential.21.attention.query_key_value.bias:
- 1656
sequential.21.attention.query_key_value.weight:
- 1656
- 552
sequential.21.input_layernorm.bias:
- 552
sequential.21.input_layernorm.weight:
- 552
sequential.21.mlp.dense_4h_to_h.bias:
- 552
sequential.21.mlp.dense_4h_to_h.weight:
- 552
- 2208
sequential.21.mlp.dense_h_to_4h.bias:
- 2208
sequential.21.mlp.dense_h_to_4h.weight:
- 2208
- 552
sequential.21.post_attention_layernorm.bias:
- 552
sequential.21.post_attention_layernorm.weight:
- 552
sequential.22.attention.dense.bias:
- 552
sequential.22.attention.dense.weight:
- 552
- 552
sequential.22.attention.query_key_value.bias:
- 1656
sequential.22.attention.query_key_value.weight:
- 1656
- 552
sequential.22.input_layernorm.bias:
- 552
sequential.22.input_layernorm.weight:
- 552
sequential.22.mlp.dense_4h_to_h.bias:
- 552
sequential.22.mlp.dense_4h_to_h.weight:
- 552
- 2208
sequential.22.mlp.dense_h_to_4h.bias:
- 2208
sequential.22.mlp.dense_h_to_4h.weight:
- 2208
- 552
sequential.22.post_attention_layernorm.bias:
- 552
sequential.22.post_attention_layernorm.weight:
- 552
sequential.23.attention.dense.bias:
- 552
sequential.23.attention.dense.weight:
- 552
- 552
sequential.23.attention.query_key_value.bias:
- 1656
sequential.23.attention.query_key_value.weight:
- 1656
- 552
sequential.23.input_layernorm.bias:
- 552
sequential.23.input_layernorm.weight:
- 552
sequential.23.mlp.dense_4h_to_h.bias:
- 552
sequential.23.mlp.dense_4h_to_h.weight:
- 552
- 2208
sequential.23.mlp.dense_h_to_4h.bias:
- 2208
sequential.23.mlp.dense_h_to_4h.weight:
- 2208
- 552
sequential.23.post_attention_layernorm.bias:
- 552
sequential.23.post_attention_layernorm.weight:
- 552
sequential.24.attention.dense.bias:
- 552
sequential.24.attention.dense.weight:
- 552
- 552
sequential.24.attention.query_key_value.bias:
- 1656
sequential.24.attention.query_key_value.weight:
- 1656
- 552
sequential.24.input_layernorm.bias:
- 552
sequential.24.input_layernorm.weight:
- 552
sequential.24.mlp.dense_4h_to_h.bias:
- 552
sequential.24.mlp.dense_4h_to_h.weight:
- 552
- 2208
sequential.24.mlp.dense_h_to_4h.bias:
- 2208
sequential.24.mlp.dense_h_to_4h.weight:
- 2208
- 552
sequential.24.post_attention_layernorm.bias:
- 552
sequential.24.post_attention_layernorm.weight:
- 552
sequential.26.norm.bias:
- 552
sequential.26.norm.weight:
- 552
sequential.27.final_linear.weight:
- null
- 552
sequential.3.attention.dense.bias:
- 552
sequential.3.attention.dense.weight:
- 552
- 552
sequential.3.attention.query_key_value.bias:
- 1656
sequential.3.attention.query_key_value.weight:
- 1656
- 552
sequential.3.input_layernorm.bias:
- 552
sequential.3.input_layernorm.weight:
- 552
sequential.3.mlp.dense_4h_to_h.bias:
- 552
sequential.3.mlp.dense_4h_to_h.weight:
- 552
- 2208
sequential.3.mlp.dense_h_to_4h.bias:
- 2208
sequential.3.mlp.dense_h_to_4h.weight:
- 2208
- 552
sequential.3.post_attention_layernorm.bias:
- 552
sequential.3.post_attention_layernorm.weight:
- 552
sequential.4.attention.dense.bias:
- 552
sequential.4.attention.dense.weight:
- 552
- 552
sequential.4.attention.query_key_value.bias:
- 1656
sequential.4.attention.query_key_value.weight:
- 1656
- 552
sequential.4.input_layernorm.bias:
- 552
sequential.4.input_layernorm.weight:
- 552
sequential.4.mlp.dense_4h_to_h.bias:
- 552
sequential.4.mlp.dense_4h_to_h.weight:
- 552
- 2208
sequential.4.mlp.dense_h_to_4h.bias:
- 2208
sequential.4.mlp.dense_h_to_4h.weight:
- 2208
- 552
sequential.4.post_attention_layernorm.bias:
- 552
sequential.4.post_attention_layernorm.weight:
- 552
sequential.5.attention.dense.bias:
- 552
sequential.5.attention.dense.weight:
- 552
- 552
sequential.5.attention.query_key_value.bias:
- 1656
sequential.5.attention.query_key_value.weight:
- 1656
- 552
sequential.5.input_layernorm.bias:
- 552
sequential.5.input_layernorm.weight:
- 552
sequential.5.mlp.dense_4h_to_h.bias:
- 552
sequential.5.mlp.dense_4h_to_h.weight:
- 552
- 2208
sequential.5.mlp.dense_h_to_4h.bias:
- 2208
sequential.5.mlp.dense_h_to_4h.weight:
- 2208
- 552
sequential.5.post_attention_layernorm.bias:
- 552
sequential.5.post_attention_layernorm.weight:
- 552
sequential.6.attention.dense.bias:
- 552
sequential.6.attention.dense.weight:
- 552
- 552
sequential.6.attention.query_key_value.bias:
- 1656
sequential.6.attention.query_key_value.weight:
- 1656
- 552
sequential.6.input_layernorm.bias:
- 552
sequential.6.input_layernorm.weight:
- 552
sequential.6.mlp.dense_4h_to_h.bias:
- 552
sequential.6.mlp.dense_4h_to_h.weight:
- 552
- 2208
sequential.6.mlp.dense_h_to_4h.bias:
- 2208
sequential.6.mlp.dense_h_to_4h.weight:
- 2208
- 552
sequential.6.post_attention_layernorm.bias:
- 552
sequential.6.post_attention_layernorm.weight:
- 552
sequential.7.attention.dense.bias:
- 552
sequential.7.attention.dense.weight:
- 552
- 552
sequential.7.attention.query_key_value.bias:
- 1656
sequential.7.attention.query_key_value.weight:
- 1656
- 552
sequential.7.input_layernorm.bias:
- 552
sequential.7.input_layernorm.weight:
- 552
sequential.7.mlp.dense_4h_to_h.bias:
- 552
sequential.7.mlp.dense_4h_to_h.weight:
- 552
- 2208
sequential.7.mlp.dense_h_to_4h.bias:
- 2208
sequential.7.mlp.dense_h_to_4h.weight:
- 2208
- 552
sequential.7.post_attention_layernorm.bias:
- 552
sequential.7.post_attention_layernorm.weight:
- 552
sequential.8.attention.dense.bias:
- 552
sequential.8.attention.dense.weight:
- 552
- 552
sequential.8.attention.query_key_value.bias:
- 1656
sequential.8.attention.query_key_value.weight:
- 1656
- 552
sequential.8.input_layernorm.bias:
- 552
sequential.8.input_layernorm.weight:
- 552
sequential.8.mlp.dense_4h_to_h.bias:
- 552
sequential.8.mlp.dense_4h_to_h.weight:
- 552
- 2208
sequential.8.mlp.dense_h_to_4h.bias:
- 2208
sequential.8.mlp.dense_h_to_4h.weight:
- 2208
- 552
sequential.8.post_attention_layernorm.bias:
- 552
sequential.8.post_attention_layernorm.weight:
- 552
sequential.9.attention.dense.bias:
- 552
sequential.9.attention.dense.weight:
- 552
- 552
sequential.9.attention.query_key_value.bias:
- 1656
sequential.9.attention.query_key_value.weight:
- 1656
- 552
sequential.9.input_layernorm.bias:
- 552
sequential.9.input_layernorm.weight:
- 552
sequential.9.mlp.dense_4h_to_h.bias:
- 552
sequential.9.mlp.dense_4h_to_h.weight:
- 552
- 2208
sequential.9.mlp.dense_h_to_4h.bias:
- 2208
sequential.9.mlp.dense_h_to_4h.weight:
- 2208
- 552
sequential.9.post_attention_layernorm.bias:
- 552
sequential.9.post_attention_layernorm.weight:
- 552
